{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all datasets and their properties\n",
    "openml.datasets.list_datasets(output_format=\"dataframe\")\n",
    "\n",
    "# Get dataset by ID\n",
    "dataset = openml.datasets.get_dataset(1476)\n",
    "\n",
    "# Get the data itself as a dataframe (or otherwise)\n",
    "X, _, _, _ = dataset.get_data(dataset_format=\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 1:\n",
    "\n",
    "This archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations.\n",
    "The goal is to achieve good performance (or as low degradation as possible) over time, as reported in the paper mentioned below in Section 2: Data collection.\n",
    "The primary purpose of providing this dataset is to make it freely accessible online to the chemo-sensor research community and artificial intelligence to develop strategies to cope with sensor/concept drift. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\n",
    "The dataset was gathered within January 2007 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego.\n",
    "Being completely operated by a fully computerized environment controlled by a LabVIEW's National Instruments software on a PC fitted with the appropriate serial data acquisition boards. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors for compensating real drift.\n",
    "The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv\n",
    "\n",
    "Answer to question 2:\n",
    "\n",
    "There was no need to make any changes in order to import the dataset. \n",
    "\n",
    "Answer to question 3:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparation of the Dataset \n",
    "X = X.astype('int64')\n",
    "y = X['Class']\n",
    "X = X.drop(columns=['Class'])\n",
    "X,y = shuffle(X,y,random_state=0)\n",
    "X = X.reset_index(drop= True)\n",
    "y = y.reset_index(drop= True)\n",
    "\n",
    "#There are no null values\n",
    "X.isna().sum().sum()\n",
    "y.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test split\n",
    "\n",
    "Xtrain = X[0:int(0.7*len(X))]\n",
    "Xtest = X[int(0.7*len(X))+1:]\n",
    "ytrain = y[0:int(0.7*len(X))]\n",
    "ytest = y[int(0.7*len(X))+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
    "dummy_clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Mean Accuracy\n",
    "\n",
    "\n",
    "# F1 Score \n",
    "f1Score = f1_score(ytest, dummy_clf.predict(Xtest), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
    "acc_score = []\n",
    "f1_scores = []\n",
    "kf = KFold(n_splits=10, random_state=None)\n",
    "\n",
    "for train_index , test_index in kf.split(Xtrain):\n",
    "    X_train , X_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "     \n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    pred_values = dummy_clf.predict(X_test)\n",
    "     \n",
    "    accuracy = dummy_clf.score(pred_values, y_test)\n",
    "    acc_score.append(accuracy)\n",
    "\n",
    "    f1Score = f1_score(y_test, dummy_clf.predict(X_test), average='macro')\n",
    "    f1_scores.append(f1Score)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "846e9557d80d190f9a7f4ea8a91daae54d434e9bf57f1dd575644ba6159713e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
